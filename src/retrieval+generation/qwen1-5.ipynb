{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbe40b9",
   "metadata": {},
   "source": [
    "### This Notebook is for Retrieving data with e5-small-v2 embedding model and generate answers with Mistral7b LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b42cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qdrant_models\n",
    "import pandas as pd\n",
    "\n",
    "MODEL_NAME = \"intfloat/e5-small-v2\"\n",
    "QDRANT_HOST = \"localhost\"\n",
    "QDRANT_PORT = 6333\n",
    "COLLECTION_NAME = \"pmc_e5_full_docs\"\n",
    "EMBED_DIM = 384\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc043da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant connection ok\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text):\n",
    "    inp = f\"passage: {text.strip()}\"\n",
    "    encoded = tokenizer(inp, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    if torch.cuda.is_available():\n",
    "        encoded = {k: v.cuda() for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        out = model(**encoded)\n",
    "    return out.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "print(\"Qdrant connection ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved context: Title: How is family health history discussed in routine primary healthcare? A qualitative study of archived family doctor consultations\n",
      "Abstract: Family health history underpins genetic medicine. Our study aimed to explore language and patterns of communication relating to family health history observed in interactions between general practitioners (GPs) and their patients within routine primary care consultations. Secondary analysis of patient and GP routine consultation data (n=252). Consultations that included ‘family health history’ were eligible for inclusion (n=58). A qualitative inductive analysis of the interactions from consultation transcripts. 46/58 conversations about family health history were initiated by the GP. Most discussions around family history lasted for between approximately 1 to 2 min. Patients were invited to share family health history through one of two ways: non-specific enquiry (eg, by asking the patient about ‘anything that runs in the family’); or specific enquiry where they were asked if they had a ‘strong family history’ in relation to a particular condition, for example, breast cancer. Patients often responded to either approach with a simple no, but fuller negative responses also occurred regularly and typically included an account of some kind (eg, explaining family relationships/dynamics which impeded or prevented the accessibility of information). Family health history is regarded as a genetic test and is embedded in the sociocultural norms of the patient from whom information is being sought. Our findings highlight that it is more complex than asking simply if ‘anything’ runs in the family. As the collection of family health history is expected to be more routine, it will be important to also consider it from sociocultural perspectives in order to help mitigate any inequities in how family history is collected, and therefore used (or not) in a person’s healthcare. Orientating an enquiry away from ‘anything’ and asking more specific details about particular conditions may help facilitate the dialogue.\n",
      "\n",
      "Title: The Enduring Effects of COVID for Cancer Care: Learning from Real-Life Clinical Practice\n",
      "Abstract: For three years, COVID-19 has circulated among our communities and around the world, fundamentally changing social interactions, health care systems, and service delivery. For people living with (and receiving treatment for) cancer, pandemic conditions presented significant additional hurdles in an already unstable and shifting environment, including disrupted personal contact with care providers, interrupted access to clinical trials, distanced therapeutic encounters, multiple immune vulnerabilities, and new forms of financial precarity. In a 2020 perspective in this journal, we examined how COVID-19 was reshaping cancer care in the early stages of the pandemic and how these changes might endure into the future. Three years later, and in light of a series of interviews with patients and their caregivers from the United States and Australia conducted during the pandemic, we return to consider the potential legacy effects of the pandemic on cancer care. While some challenges to care provision and survivorship were unforeseen, others accentuated and amplified existing problems experienced by patients, caregivers, and health care providers. Both are likely to have enduring effects in the “post-pandemic” world, raising the importance of focusing on lessons that can be learned for the future.\n",
      "\n",
      "Title: Patient safety and the COVID-19 pandemic: a qualitative study of perspectives of front-line clinicians\n",
      "Abstract: Studies on the impacts of COVID-19 on patient safety are emerging. However, few studies have elicited the perspectives of front-line clinicians. We interviewed clinicians from 16 US hospitals who worked in the emergency department, intensive care unit or inpatient unit during the COVID-19 pandemic. We asked about their experiences with both clinician well-being and patient care throughout the pandemic. We used a rigorous thematic analysis to code the interview transcripts. This study was part of a larger randomised control trial of an intervention to improve healthcare worker well-being during the COVID-19 pandemic; the findings described here draw from clinicians who spontaneously raised issues related to patient safety. 11 physicians and 16 nurses in our sample raised issues related to patient safety. We identified two primary themes: compromised access to healthcare and impaired care delivery. First, clinicians discussed how changes in access to healthcare early in the pandemic–including a shift to telehealth and deferred care–led to delays in accurate diagnosis and patients presenting later in their disease course. Second, clinicians discussed the effects of COVID-19 on care delivery related to staffing, equipment shortages and space constraints and how they deviated from the standard of care to manage these constraints. Clinicians noted how these issues led to patient safety events such as central line infections, patient falls and serious medication administration errors. Several well-intentioned interventions implemented in the early weeks of the pandemic created a unique context that affected patient safety throughout the pandemic. Future pandemic preparedness should consider planning that incorporates a patient safety lens to mitigate further harm from occurring during a public health crisis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krtgi\\AppData\\Local\\Temp\\ipykernel_21732\\2068477162.py:5: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  hits = client.search(\n"
     ]
    }
   ],
   "source": [
    "query = \"Prompting Primary Care Providers about Increased Patient Risk As a Result of Family History: Does It Work?\"\n",
    "query_emb = get_embedding(query)\n",
    "\n",
    "hits = client.search(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_emb.tolist(),\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "context_chunks = []\n",
    "for hit in hits:\n",
    "    p = hit.payload\n",
    "    chunk = []\n",
    "    if p.get(\"title\"):\n",
    "        chunk.append(f\"Title: {p['title']}\")\n",
    "    if p.get(\"abstract\"):\n",
    "        chunk.append(f\"Abstract: {p['abstract']}\")\n",
    "\n",
    "    \n",
    "    context_chunks.append(\"\\n\".join(chunk))\n",
    "\n",
    "retrieved_context = \"\\n\\n---\\n\\n\".join(context_chunks)\n",
    "\n",
    "\n",
    "retrieved_context = \"\\n\\n\".join(context_chunks)\n",
    "print(\"Retrieved context:\", retrieved_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "736a4771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen1.5-1.8B-Chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\n",
    "    \"You are PubMed QA-Bot, a cautious biomedical expert.\\n\"\n",
    "    \"• Read the CONTEXT exactly as given—do not invent facts.\\n\"\n",
    "    \"• If the answer is present, quote or paraphrase only material you can trace to a specific sentence in the CONTEXT.\\n\"\n",
    "    \"• If the answer is partly or wholly absent, reply exactly with: 'INSUFFICIENT CONTEXT'.\\n\"\n",
    "    \"• Use concise scientific language and original terminology from the CONTEXT.\\n\"\n",
    "    \"• Write the ANSWER in ≤ 40 words. Do NOT include citations in the ANSWER line.\\n\"\n",
    "    \"• After the ANSWER, output a line that starts with 'EVIDENCE:' followed by the sentence IDs you used.\\n\"\n",
    ")\n",
    "\n",
    "demo_user = (\n",
    "    \"QUESTION:\\nWhat is the main benefit of opioid patient-controlled therapy (PCT) in palliative care patients?\\n\\n\"\n",
    "    \"CONTEXT:\\n\"\n",
    "    \"[1] Opioid PCT allows patients to self-administer small boluses...\\n\"\n",
    ")\n",
    "demo_assistant = (\n",
    "    \"ANSWER: Opioid PCT safely reduces refractory breathlessness in palliative patients while giving them direct symptom control.\\n\"\n",
    "    \"EVIDENCE: 1-2\"\n",
    ")\n",
    "\n",
    "user_message = (\n",
    "    f\"QUESTION:\\n{query}\\n\\n\"\n",
    "    f\"CONTEXT:\\n{retrieved_context}\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    # {\"role\": \"user\", \"content\": demo_user},\n",
    "    # {\"role\": \"assistant\", \"content\": demo_assistant},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a84a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 1147\n",
      "Tokenization complete\n",
      "Prompt length: 6223\n",
      "Question: Prompting Primary Care Providers about Increased Patient Risk As a Result of Family History: Does It Work?\n",
      "Answer: EVIDENCE: \n",
      "1. \"Family health history is regarded as a genetic test and is embedded in the sociocultural norms of the patient from whom information is being sought.\" - Sentence ID: 3\n",
      "2. \"Our findings highlight that it is more complex than asking simply if ‘anything’ runs in the family.\" - Sentence ID: 46\n",
      "3. \"As the collection of family health history is expected to be more routine, it will be important to also consider it from sociocultural perspectives in order to help mitigate any inequities in how family history is collected, and therefore used (or not) in a person's healthcare.\" - Sentence ID: 58\n",
      "4. \"Both are likely to have enduring effects in the post-pandemic world, raising the importance of focusing on lessons that can be learned for the future.\" - Sentence ID: 70\n",
      "5. \"We identified two primary themes: compromised access to healthcare and impaired care delivery.\" - Sentence ID: 71\n",
      "6. \"First, clinicians discussed how changes in access to healthcare early in the pandemic – including a shift to telehealth and deferred care – led to delays in accurate diagnosis and patients presenting later in their disease course.\" - Sentence ID: 72\n",
      "7. \"Second, clinicians discussed the effects of COVID-19 on care delivery related to staffing, equipment shortages and space constraints and how they deviated from the standard of care to manage these constraints.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "print(\"Token count:\", len(tokenizer(prompt)[\"input_ids\"]))\n",
    "\n",
    "print(\"Tokenization complete\")\n",
    "\n",
    "print(\"Prompt length:\", len(prompt))\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=300,\n",
    "    do_sample=False\n",
    ")\n",
    "generated = outputs[0][inputs[\"input_ids\"].shape[1]:]\n",
    "answer = tokenizer.decode(generated, skip_special_tokens=True).strip()\n",
    "\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
